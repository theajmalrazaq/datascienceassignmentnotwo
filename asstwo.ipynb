{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a91297",
   "metadata": {},
   "source": [
    "### Importing all libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e90039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67699a0",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbfd79",
   "metadata": {},
   "source": [
    "### Identifying unique channel names before standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Channel\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a351e",
   "metadata": {},
   "source": [
    "### Correct Channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Channel'] = df['Channel'].replace({\n",
    "    \"geo\": \"Geo News\",\n",
    "    \"Geo\": \"Geo News\",\n",
    "    \"GEO NEWS\": \"Geo News\",\n",
    "    \"ARY\": \"ARY News\",\n",
    "    \"ary\": \"ARY News\",\n",
    "    \"ARYNEWS\": \"ARY News\",\n",
    "    \"Samaa\": \"Samaa TV\",\n",
    "    \"SAMAA TV\": \"Samaa TV\",\n",
    "    \"Express\": \"Express News\",\n",
    "    \"Express-News\": \"Express News\",\n",
    "    \"hum news\": \"Hum News\",\n",
    "    \"HUM News\": \"Hum News\",\n",
    "    \"DawnNews\": \"Dawn News\",\n",
    "    \"DAWN\": \"Dawn News\"\n",
    "})\n",
    "\n",
    "print(df['Channel'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1befbc",
   "metadata": {},
   "source": [
    "### Find All Journalist Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9adb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Journalist\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ab79c",
   "metadata": {},
   "source": [
    "### Makes Journalist Name Consistant and fix spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Journalist\"] = df[\"Journalist\"].str.title()\n",
    "df[\"Journalist\"] = df[\"Journalist\"].replace({\n",
    "    \"Rauf Klassra\": \"Rauf Klasra\",\n",
    "    \"Mohsin Raza Khan\": \"Mohsin Raza\",\n",
    "    \"K. Khan\": \"Kamran Khan\",\n",
    "})\n",
    "print(df[\"Journalist\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b1fba",
   "metadata": {},
   "source": [
    "### Identify all cities and Regions names to standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ff940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"City\"].unique())\n",
    "print(df[\"Region\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90e2ed",
   "metadata": {},
   "source": [
    "### Map Cities to Correct Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6404f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region_city_map = {\n",
    "    'Punjab': ['Lahore', 'Multan', 'Rawalpindi'],\n",
    "    'Sindh': ['Karachi', 'Hyderabad'],\n",
    "    'KPK': ['Peshawar'],\n",
    "    'Balochistan': ['Quetta'],\n",
    "    'Islamabad': ['Islamabad'],\n",
    "    'AJK': ['Muzaffarabad']\n",
    "}\n",
    "\n",
    "def correct_region(row):\n",
    "    # rule 1: if region is AJK always set city to Muzaffarabad\n",
    "    if row['Region'] == 'AJK':\n",
    "        row['City'] = 'Muzaffarabad'\n",
    "        return row\n",
    "\n",
    "    # rule 2: for non-AJK regions fix region according to city\n",
    "    for region, cities in region_city_map.items():\n",
    "        if row['City'] in cities:\n",
    "            row['Region'] = region\n",
    "            return row\n",
    "    return row\n",
    "\n",
    "df = df.apply(correct_region, axis=1)\n",
    "\n",
    "\n",
    "display(df[['City', 'Region']].drop_duplicates().sort_values(by='City').reset_index(drop=True))\n",
    "print(df[\"Region\"].unique())\n",
    "print(df[\"City\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4d273",
   "metadata": {},
   "source": [
    "### Identify all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Topic\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e43399",
   "metadata": {},
   "source": [
    "### Fix topic based on headlines\n",
    "   Doing manually based on keyword parmanent solution involve NLP use models to predict topic based on headline it miss edge cases like if headline conatins keywords from 2 or more categorzies it gives topic bases on what comes first\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1bcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_keywords = {\n",
    "    \"Health\": [\n",
    "        \"hospital\", \"doctor\", \"virus\", \"covid\", \"vaccine\", \"cases\", \"patients\",\n",
    "        \"medicine\", \"shortage\", \"disease\", \"pandemic\", \"healthcare\", \"polio\", \"dengue\"\n",
    "    ],\n",
    "    \"Economy\": [\n",
    "        \"budget\", \"imf\", \"inflation\", \"tax\", \"deficit\", \"exports\", \"imports\",\n",
    "        \"trade\", \"revenue\", \"market\", \"stock\", \"growth\", \"investment\", \"finance\"\n",
    "    ],\n",
    "    \"Terrorism\": [\n",
    "        \"attack\", \"blast\", \"bomb\", \"terrorist\", \"militant\", \"explosion\", \"security\",\n",
    "        \"waziristan\", \"operation\", \"killed\", \"army\", \"soldier\", \"convoy\", \"suicide\"\n",
    "    ],\n",
    "    \"Sports\": [\n",
    "        \"match\", \"cricket\", \"football\", \"hockey\", \"win\", \"tournament\", \"player\",\n",
    "        \"psl\", \"worldcup\", \"babar\", \"qalandars\", \"karachi kings\", \"series\"\n",
    "    ],\n",
    "    \"Politics\": [\n",
    "        \"election\", \"government\", \"assembly\", \"minister\", \"prime\", \"party\",\n",
    "        \"pmln\", \"ppp\", \"pti\", \"parliament\", \"cabinet\", \"bill\", \"opposition\", \"rally\"\n",
    "    ],\n",
    "    \"Crime\": [\n",
    "        \"murder\", \"arrested\", \"robbery\", \"police\", \"shooting\", \"kidnapping\",\n",
    "        \"theft\", \"suspect\", \"gang\", \"investigation\", \"crime\", \"violence\", \"court\"\n",
    "    ],\n",
    "    \"Judiciary\": [\n",
    "        \"court\", \"judge\", \"justice\", \"supreme\", \"high\", \"petition\", \"case\",\n",
    "        \"hearing\", \"bench\", \"verdict\", \"order\", \"lawyer\", \"bar\", \"judicial\"\n",
    "    ],\n",
    "    \"Environment\": [\n",
    "        \"flood\", \"rain\", \"climate\", \"weather\", \"storm\", \"pollution\", \"temperature\",\n",
    "        \"heatwave\", \"earthquake\", \"relief\", \"disaster\", \"ndma\", \"environment\"\n",
    "    ],\n",
    "    \"Media\": [\n",
    "        \"journalist\", \"anchor\", \"channel\", \"pemra\", \"censorship\", \"press\",\n",
    "        \"freedom\", \"reporter\", \"tv\", \"news\", \"media\", \"talkshow\", \"backlash\"\n",
    "    ],\n",
    "    \"Education\": [\n",
    "        \"school\", \"teacher\", \"student\", \"university\", \"exam\", \"degree\",\n",
    "        \"curriculum\", \"education\", \"hec\", \"scholarship\", \"college\", \"protest\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def correct_topic(row):\n",
    "    headline = row['Headline'].lower()\n",
    "    current_topic = row['Topic']\n",
    "    for topic, keywords in topic_keywords.items():\n",
    "        if any(kw in headline for kw in keywords):\n",
    "            return topic\n",
    "    return current_topic\n",
    "\n",
    "df['Topic'] = df.apply(correct_topic, axis=1)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95310ee",
   "metadata": {},
   "source": [
    "### Identifying jurnalist domains and adding flags and counting matches and mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51864152",
   "metadata": {},
   "outputs": [],
   "source": [
    "journalist_domain = {\n",
    "    \"Najam Sethi\": [\"Politics\", \"Media\", \"Sports\"],\n",
    "    \"Dr. Shahid Masood\": [\"Politics\", \"Judiciary\"],\n",
    "    \"Kamran Shahid\": [\"Politics\", \"Media\"],\n",
    "    \"Matiullah Jan\": [\"Judiciary\", \"Politics\"],\n",
    "    \"Rauf Klasra\": [\"Politics\", \"Economy\"],\n",
    "    \"Ansar Abbasi\": [\"Judiciary\", \"Politics\"],\n",
    "    \"Umar Cheema\": [\"Crime\", \"Politics\"],\n",
    "    \"Shahzeb Khanzada\": [\"Politics\", \"Economy\", \"Media\"],\n",
    "    \"Kamran Khan\": [\"Politics\", \"Economy\", \"Sports\", \"Media\"],\n",
    "    \"Asma Shirazi\": [\"Politics\", \"Media\"],\n",
    "    \"Mohsin Raza\": [\"Media\", \"Politics\"],\n",
    "    \"Saleem Safi\": [\"Politics\", \"Terrorism\"],\n",
    "    \"Talat Hussain\": [\"Politics\", \"Media\"],\n",
    "    \"Owais Tohid\": [\"Media\", \"Politics\"],\n",
    "    \"Nusrat Javed\": [\"Politics\", \"Media\"]\n",
    "}\n",
    "df[\"ExpectedDomain\"] = df[\"Journalist\"].map(journalist_domain)\n",
    "def check_mismatch(row):\n",
    "    expected = row[\"ExpectedDomain\"]\n",
    "    topic = row[\"Topic\"]\n",
    "    if topic in expected:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df[\"DomainFlag\"] = df.apply(check_mismatch, axis=1)\n",
    "display(df[[\"Journalist\", \"Topic\", \"ExpectedDomain\", \"DomainFlag\"]].head(10))\n",
    "print(df[\"DomainFlag\"].value_counts()) # Print the counts of matches and mismatches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50eefa",
   "metadata": {},
   "source": [
    "### Checking incositences in newspaper if exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422283e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Newspaper\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9575e93",
   "metadata": {},
   "source": [
    "### Identiying and fixing revenue & AdSpend uints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pkr(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return x\n",
    "    s = str(x).lower().replace(',', '').strip()\n",
    "    if 'million' in s:\n",
    "        num = float(re.search(r'[\\d\\.]+', s).group())\n",
    "        return num * 1_000_000\n",
    "    if 'lakh' in s or 'lac' in s:\n",
    "        num = float(re.search(r'[\\d\\.]+', s).group())\n",
    "        return num * 100_000\n",
    "    if 'crore' in s or 'cr' in s:\n",
    "        num = float(re.search(r'[\\d\\.]+', s).group())\n",
    "        return num * 10_000_000\n",
    "    # fallback numeric\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df['Revenue'] = df['Revenue'].apply(convert_to_pkr)\n",
    "df['AdSpend'] = df['AdSpend'].apply(convert_to_pkr)\n",
    "# df['Revenue'] = df['Revenue'].apply(lambda x: int(np.floor(x)) if pd.notna(x) else np.nan)\n",
    "# df['AdSpend'] = df['AdSpend'].apply(lambda x: int(np.floor(x)) if pd.notna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c8b39",
   "metadata": {},
   "source": [
    "### Fixing negative airtime value\n",
    " It is better to fill them with nan insted of positive so data dont become distorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Airtime'] = df['Airtime'].apply(lambda x: x if x is not None and x >= 0 else np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0800e4c",
   "metadata": {},
   "source": [
    "### Fixing Out of limit TRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ratings'] = df['Ratings'].apply(lambda x: np.nan if pd.isna(x) or x < 0 else min(x, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5af612",
   "metadata": {},
   "source": [
    "### Fixing controversy inconsisteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ControversyFlag'] = df['ControversyFlag'].replace({\n",
    "    'Yes': '1',\n",
    "    'No': '0',\n",
    "    '': np.nan\n",
    "})\n",
    "print(df[\"ControversyFlag\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e4fe5",
   "metadata": {},
   "source": [
    "### fixing inconsistence in missing flag col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MissingDataFlag'] = df.notna().all(axis=1).astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9abcc5",
   "metadata": {},
   "source": [
    "### fixing bisas scroing using tanh squashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e975026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BiasScore\"] = np.tanh(df[\"BiasScore\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49de9b",
   "metadata": {},
   "source": [
    "### Fixing incorrect Language entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a47ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Language\"] = df[\"Language\"].replace({\n",
    "    \"urdu\": \"Urdu\",\n",
    "    \"ENG\": \"English\",})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
